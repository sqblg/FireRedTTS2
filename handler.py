import runpod
import os
import sys
import json
import traceback
import base64
import shutil  # ğŸ”µ [æ–°å¢] ç”¨äºåˆ é™¤åæ‰çš„æ–‡ä»¶å¤¹
from datetime import datetime
import torch
import torchaudio
import boto3
from botocore.client import Config
from supabase import create_client
from huggingface_hub import snapshot_download  # ğŸ”µ [æ–°å¢] æ ¸å¿ƒä¸‹è½½å·¥å…·
import gc

# ==================== ç¯å¢ƒå˜é‡ ====================
# è¯·åœ¨ RunPod æ§åˆ¶å°çš„ Environment Variables ä¸­è®¾ç½®è¿™äº›å€¼
SUPABASE_URL = os.environ.get("SUPABASE_URL", "")
SUPABASE_SERVICE_KEY = os.environ.get("SUPABASE_SERVICE_KEY", "")

R2_ACCESS_KEY_ID = os.environ.get("R2_ACCESS_KEY_ID", "")
R2_SECRET_ACCESS_KEY = os.environ.get("R2_SECRET_ACCESS_KEY", "")
R2_ACCOUNT_ID = os.environ.get("R2_ACCOUNT_ID", "")
R2_BUCKET_NAME = os.environ.get("R2_BUCKET_NAME", "blockfm-audio")
R2_REGION = os.environ.get("R2_REGION", "auto")
R2_PUBLIC_URL = os.environ.get("R2_PUBLIC_URL", "https://audio.blockfm.io")

# èµ„äº§è·¯å¾„ï¼ˆå¯¹åº”æ‚¨ä»“åº“æ ¹ç›®å½•çš„ä½ç½®ï¼‰
# é»˜è®¤ Docker è·¯å¾„ä¸º /app
ASSETS_DIR = os.environ.get("ASSETS_DIR", "/app/assets")
PROMPT_TEXTS_FILE = os.environ.get("PROMPT_TEXTS_FILE", "/app/prompt_texts.json")

# æ¨¡å‹è·¯å¾„
# å…³é”®ï¼šå¿…é¡»æŒ‡å‘ Network Volume æŒ‚è½½ç‚¹
MODEL_DIR = os.environ.get("MODEL_DIR", "/runpod-volume/FireRedTTS2")

LANG_ISO_TO_NAME = {
    'zh': 'Chinese', 'en': 'English', 'ja': 'Japanese',
    'ko': 'Korean', 'de': 'German', 'fr': 'French', 'ru': 'Russian'
}

# ==================== å…¨å±€çŠ¶æ€ ====================
_supabase_client = None
_r2_client = None
_tts_model = None

def get_supabase_client():
    global _supabase_client
    if _supabase_client is None:
        from supabase import create_client
        _supabase_client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)
    return _supabase_client

def get_r2_client():
    global _r2_client
    if _r2_client is None:
        import boto3
        from botocore.client import Config
        _r2_client = boto3.client(
            's3',
            aws_access_key_id=R2_ACCESS_KEY_ID,
            aws_secret_access_key=R2_SECRET_ACCESS_KEY,
            region_name=R2_REGION,
            endpoint_url=f"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com",
            config=Config(signature_version='s3v4')
        )
    return _r2_client

def get_tts_model():
    """
    æƒ°æ€§è·å– TTS æ¨¡å‹ (å¢å¼ºç‰ˆï¼šä½¿ç”¨ snapshot_download)
    """
    global _tts_model
    if _tts_model is None:
        print(f"ğŸš€ Checking model integrity in: {MODEL_DIR}")
        
        # 1. æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (ä½œä¸ºä¸‹è½½æˆåŠŸçš„æ ‡å¿—)
        # FireRedTTS2 çš„æ ¸å¿ƒæƒé‡æ–‡ä»¶
        required_files = ["config_llm.json", "codec.pt"] 
        is_complete = os.path.exists(MODEL_DIR) and any(
            os.path.exists(os.path.join(MODEL_DIR, f)) for f in required_files
        )

        if not is_complete:
            print("   ğŸ“¥ Model missing or incomplete. Starting intelligent download...")
            
            # 2. æ¸…ç†æ®‹ä½™ (è§£å†³ git exit code 128 çš„å…³é”®)
            # å¦‚æœæ–‡ä»¶å¤¹å­˜åœ¨ä½†æ–‡ä»¶ä¸é½ï¼Œè¯´æ˜ä¸Šæ¬¡ä¸‹è½½æ–­äº†ã€‚è™½ç„¶ snapshot_download æ”¯æŒæ–­ç‚¹ï¼Œ
            # ä½†ä¸ºäº†ä¿é™©ï¼Œå¦‚æœå‘ç°æ˜¯ä¸ªç©ºå£³æ–‡ä»¶å¤¹ï¼Œç›´æ¥åˆ æ‰é‡æ¥ã€‚
            if os.path.exists(MODEL_DIR) and not os.listdir(MODEL_DIR):
                 print("   ğŸ§¹ Removing empty directory to prevent conflicts...")
                 os.rmdir(MODEL_DIR)

            try:
                # 3. ä½¿ç”¨å®˜æ–¹ SDK ä¸‹è½½ (æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä¸ä¼šæŠ¥é”™æ–‡ä»¶å¤¹å·²å­˜åœ¨)
                snapshot_download(
                    repo_id="FireRedTeam/FireRedTTS2",
                    local_dir=MODEL_DIR,
                    resume_download=True,
                    max_workers=8
                )
                print("   âœ… Download complete.")
            except Exception as e:
                print(f"   âŒ Download failed: {e}")
                # æŠ›å‡ºå¼‚å¸¸è®© RunPod é‡å¯ï¼Œä¸è¦ç»§ç»­å°è¯•åŠ è½½åæ¨¡å‹
                raise e
        else:
            print("   ğŸ“‚ Model integrity check passed. Using cache.")

        # 4. åŠ è½½æ¨¡å‹
        print(f"ğŸ”¥ Loading FireRedTTS2 from {MODEL_DIR}...")
        
        # ç¡®ä¿ä»£ç åº“åœ¨ path ä¸­
        # å‡è®¾ Dockerfile å·²ç»å®‰è£…äº†ä¾èµ–ï¼Œä½†æˆ‘ä»¬è¿™é‡Œæ˜¾å¼æ·»åŠ è·¯å¾„ä½œä¸ºå…œåº•
        if "/app/FireRedTTS2_Code" not in sys.path:
            sys.path.append("/app/FireRedTTS2_Code")
            
        from fireredtts2.fireredtts2 import FireRedTTS2
            
        _tts_model = FireRedTTS2(
            pretrained_dir=MODEL_DIR,
            gen_type="dialogue",
            device="cuda"
        )
        print("âœ… Model loaded successfully")
        
    return _tts_model

def get_cloning_refs(language_iso: str):
    lang_name = LANG_ISO_TO_NAME.get(language_iso)
    if not lang_name:
        raise ValueError(f"Unsupported language: {language_iso}")

    if not os.path.exists(PROMPT_TEXTS_FILE):
        raise FileNotFoundError(f"Missing prompt texts file: {PROMPT_TEXTS_FILE}")

    with open(PROMPT_TEXTS_FILE, 'r', encoding='utf-8') as f:
        all_prompt_texts = json.load(f)
    
    texts_data = all_prompt_texts.get(lang_name)
    if not texts_data:
        raise ValueError(f"Prompt texts not found for: {lang_name}")
    
    s1_text = texts_data.get('S1')
    s2_text = texts_data.get('S2')
    
    # ğŸ”´ [å…³é”®ä¿®å¤] æ·»åŠ  [S1]/[S2] æ ‡ç­¾å‰ç¼€ï¼Œä¿®å¤ AssertionError
    # ä½ çš„ JSON é‡Œæ˜¯çº¯æ–‡æœ¬ï¼Œæ¨¡å‹è¦æ±‚å¿…é¡»å¸¦æ ‡ç­¾
    s1_text_tagged = f"[S1]{s1_text}"
    s2_text_tagged = f"[S2]{s2_text}"

    s1_path = os.path.join(ASSETS_DIR, language_iso, "S1.mp3")
    s2_path = os.path.join(ASSETS_DIR, language_iso, "S2.mp3")
    
    refined_paths = []
    for p in [s1_path, s2_path]:
        if os.path.exists(p):
            refined_paths.append(p)
        else:
            alt_p = p.replace(".mp3", ".flac")
            if os.path.exists(alt_p):
                refined_paths.append(alt_p)
            else:
                raise FileNotFoundError(f"Missing asset: {p}")

    # è¿”å›å¸¦æ ‡ç­¾çš„æ–‡æœ¬
    return (refined_paths, [s1_text_tagged, s2_text_tagged])

# ==================== æ ¸å¿ƒå¤„ç†é€»è¾‘ (åŒæ­¥) ====================

def run_tts_process(episode_id: str):
    """
    åŒæ­¥æ‰§è¡Œ TTS ä»»åŠ¡ (åˆ†æ‰¹æ¨ç† + æ˜¾å­˜ä¿æŠ¤ç‰ˆ)
    """
    print(f"ğŸ”„ Processing Episode ID: {episode_id}")
    
    # ğŸŸ¢ [æ–°å¢] å¼ºåˆ¶æ˜¾å­˜æ¸…ç† (ä»»åŠ¡å¼€å§‹å‰)
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    supabase = get_supabase_client()
    tts_model = get_tts_model()
    r2_client = get_r2_client()

    # 1. è·å–ä»»åŠ¡æ•°æ®
    response = supabase.table('episodes').select('*').eq('id', episode_id).execute()
    if not response.data:
        raise ValueError(f"Episode {episode_id} not found")
    
    episode = response.data[0]
    language = episode.get('language')
    if not language: raise ValueError("Language field is missing")

    script_content = episode.get('script_content', {})
    
    # 2. æ›´æ–°çŠ¶æ€ä¸º 'tts_processing'
    print(f"   â³ Updating status to 'tts_processing'...")
    supabase.table('episodes').update({'status': 'tts_processing'}).eq('id', episode_id).execute()

    # 3. å‡†å¤‡æ–‡æœ¬ (ä¿æŒåŸæœ‰æ¸…æ´—é€»è¾‘)
    raw_dialogue = script_content.get('dialogue', [])
    text_list = []
    
    for i, d in enumerate(raw_dialogue):
        role = d.get('role', 'Guest')
        content = d.get('text', '')
        if content:
            content = content.strip()
            content = content.replace('[', 'ã€').replace(']', 'ã€‘')
        if not content: continue
        tag = '[S1]' if role == 'Host' else '[S2]'
        text_list.append(f"{tag}{content}")

    if not text_list:
        raise ValueError("Script dialogue is empty after cleaning")
        
    print(f"   ğŸ“ Prepared {len(text_list)} lines. Preview: {text_list[:2]}...")

    # 4. ğŸŸ¢ [é‡æ„] åˆ†æ‰¹æ¨ç† (Batch Inference)
    print(f"   ğŸ™ï¸ Generating audio for {episode_id}...")
    prompt_wavs, prompt_texts = get_cloning_refs(language)
    
    try:
        BATCH_SIZE = 10  # æ¯æ¬¡å¤„ç† 10 å¥
        audio_segments = []
        
        # ä½¿ç”¨ inference_mode è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜
        with torch.inference_mode():
            for i in range(0, len(text_list), BATCH_SIZE):
                batch_texts = text_list[i : i + BATCH_SIZE]
                print(f"      Processing Batch {i//BATCH_SIZE + 1}/{(len(text_list)+BATCH_SIZE-1)//BATCH_SIZE}...")
                
                # æ¨ç†å½“å‰æ‰¹æ¬¡
                wav_batch = tts_model.generate_dialogue(
                    text_list=batch_texts,
                    prompt_wav_list=prompt_wavs,
                    prompt_text_list=prompt_texts,
                    temperature=0.7,
                    topk=20
                )
                
                # æ”¶é›†ç»“æœ (æ³¨æ„ç»´åº¦å¤„ç†)
                if isinstance(wav_batch, list):
                    # å¦‚æœæ¨¡å‹è¿”å›åˆ—è¡¨ï¼Œæ‹¼æ¥æˆ Tensor
                    wav_batch = torch.cat(wav_batch, dim=1) if len(wav_batch) > 0 else torch.tensor([])
                
                # ç¡®ä¿æ˜¯ CPU Tensorï¼Œé˜²æ­¢å ç”¨æ˜¾å­˜
                audio_segments.append(wav_batch.cpu())
                
                # ğŸŸ¢ [å…³é”®] æ¯æ‰¹æ¬¡åæ¸…ç†æ˜¾å­˜
                del wav_batch
                torch.cuda.empty_cache()
        
        # æ‹¼æ¥æ‰€æœ‰æ‰¹æ¬¡
        if not audio_segments:
            raise ValueError("No audio generated")
            
        print("      Merging audio segments...")
        final_wav = torch.cat(audio_segments, dim=1)

    except AssertionError as ae:
        print(f"   ğŸ”´ Model Assertion Error! Input text format might be wrong.")
        print(f"   ğŸ”´ Debug Text List: {json.dumps(text_list, ensure_ascii=False)}")
        raise ae
    except Exception as e:
        torch.cuda.empty_cache()
        raise e

    # 5. ä¿å­˜å¹¶ä¸Šä¼  R2
    sample_rate = 24000
    tmp_path = f"/tmp/{episode_id}.wav"
    torchaudio.save(tmp_path, final_wav, sample_rate)
    duration_seconds = final_wav.shape[-1] // sample_rate

    r2_key = f"podcasts/{episode_id}.wav"
    print(f"   â˜ï¸ Uploading to R2: {r2_key}")
    with open(tmp_path, 'rb') as f:
        r2_client.put_object(
            Bucket=os.environ.get("R2_BUCKET_NAME"), 
            Key=r2_key, 
            Body=f, 
            ContentType='audio/wav'
        )
    
    # âœ… ç›´æ¥ä½¿ç”¨å…¨å±€å˜é‡ R2_PUBLIC_URL (å®ƒå·²ç»åœ¨æ–‡ä»¶å¤´éƒ¨å¤„ç†è¿‡é»˜è®¤å€¼å’Œrstripäº†)
    audio_url = f"{R2_PUBLIC_URL}/{r2_key}"

    # 6. å®Œæˆå›å†™
    print(f"   âœ… Done. Updating DB status to 'completed'...")
    supabase.table('episodes').update({
        'audio_url': audio_url,
        'duration': int(duration_seconds),
        'status': 'completed',
        'tts_updated_at': datetime.utcnow().isoformat(),
        'retry_count': 0
    }).eq('id', episode_id).execute()
    
    # æ¸…ç†
    if os.path.exists(tmp_path): os.remove(tmp_path)
    # ğŸŸ¢ [æ–°å¢] å¼ºåˆ¶æ˜¾å­˜æ¸…ç† (ä»»åŠ¡ç»“æŸå)
    del final_wav
    del audio_segments
    gc.collect()
    torch.cuda.empty_cache()

    return {"audio_url": audio_url}
# ==================== RunPod Handler ====================

def handler(job):
    """
    RunPod Serverless å…¥å£å‡½æ•°
    """
    episode_id = None
    try:
        job_input = job["input"]
        episode_id = job_input.get("episode_id")
        
        if not episode_id:
            return {"error": "Missing episode_id"}

        print(f"\nğŸ”¥ [RunPod] Starting TTS job for episode {episode_id}")
        
        # è°ƒç”¨åŒæ­¥å‡½æ•°
        result = run_tts_process(episode_id)
        
        return {"status": "success", "output": result}

    except Exception as e:
        print(f"ğŸ”´ [RunPod] Error processing episode {episode_id}: {str(e)}")
        traceback.print_exc()
        
        # å¤±è´¥å›å†™
        if episode_id:
            try:
                supabase = get_supabase_client()
                resp = supabase.table('episodes').select('retry_count').eq('id', episode_id).execute()
                if resp.data:
                    current_retry = resp.data[0].get('retry_count', 0)
                    if current_retry < 3:
                        supabase.table('episodes').update({
                            'status': 'queued',
                            'retry_count': current_retry + 1
                        }).eq('id', episode_id).execute()
                        print(f"   ğŸ”„ Episode {episode_id} re-queued (retry #{current_retry + 1})")
                    else:
                        supabase.table('episodes').update({
                            'status': 'failed'
                        }).eq('id', episode_id).execute()
                        print(f"   âŒ Episode {episode_id} marked as failed (max retries)")
            except Exception as db_err:
                print(f"   âŒ Failed to update DB status: {db_err}")
        
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    # å¯åŠ¨ RunPod Serverless Worker
    runpod.serverless.start({"handler": handler})
